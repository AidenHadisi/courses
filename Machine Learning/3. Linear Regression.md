## **Overview of Supervised Learning**
- **Definition**: Supervised learning involves training a model on a dataset where the correct answers (output) are provided.
  - **Example**: Predicting house prices based on house size.
  - Requires a **training set** containing:
    - **Input variable (Feature)**: Denoted as $x$ (e.g., house size in square feet).
    - **Output variable (Target)**: Denoted as $y$ (e.g., house price in thousands of dollars).

---

## **Linear Regression Model**
- **Purpose**: Fits a straight line to data to predict numerical outputs.
- **Use Case**:
  - Dataset: House sizes and prices in Portland.
  - Prediction: Given a house size of 1250 sq. ft., estimate the price using the best-fit line.

---

## **Visualizing the Dataset**
### **Scatter Plot**
- **Axes**:
  - Horizontal: House size ($x$) in sq. ft.
  - Vertical: House price ($y$) in thousands of dollars.
- Each data point $(x, y)$ represents a house.

### **Data Table**
| **Size (sq. ft.)** | **Price ($y$, thousands)** |
|---------------------|---------------------------|
| 2104               | 400                       |
| ...                | ...                       |
| 1250               | Predicted (e.g., 220)     |

- **Row Count ($m$)**: Total number of training examples ($m = 47$).

---

## **Standard Notation**
- **Input (Feature)**: $x$ (e.g., house size).
- **Output (Target)**: $y$ (e.g., house price).
- **Training Example**: $(x, y)$
  - Example: $(2104, 400)$
- **Indexed Example**:
  - $x^{(i)}$: Feature of the $i$-th example.
  - $y^{(i)}$: Target of the $i$-th example.
  - Example: $x^{(1)} = 2104$, $y^{(1)} = 400$.

> **Note**: Superscripts like $x^{(i)}$ are **indices**, not exponents.

---

## **Key Terminology**
| **Term**                     | **Description**                                                  |
| ---------------------------- | ---------------------------------------------------------------- |
| **Training Set**             | Dataset used to train the model.                                 |
| **Feature** ($x$)            | Input variable for prediction (e.g., house size).                |
| **Target** ($y$)             | Output variable (e.g., house price).                             |
| **Number of Examples** ($m$) | Total rows in the dataset (e.g., $m = 47$).                      |
| **Training Example** $(x,y)$ | A single training example or a specific row in the training set. |

---
# How Supervised Learning Works

## **Overview**
- **Goal of Supervised Learning**: Train a model to make predictions based on input data.
- **Key Components**:
  - **Training Set**: Contains both input features ($x$) and output targets ($y$).
  - **Model (Function $f$)**: Learns from the training set to make predictions ($\hat{y}$).

---

## **Supervised Learning Process**
1. **Input**: Training set $(x, y)$.
2. **Learning Algorithm**: Processes the training set to generate a function $f$ (the model).
3. **Output**: A function $f$ that:
   - Takes an input $x$ (e.g., house size).
   - Predicts an output $\hat{y}$ (e.g., estimated price).

---

## **Key Notations**
| **Symbol**  | **Meaning**                               |
|-------------|-------------------------------------------|
| $x$         | Input feature (e.g., house size).         |
| $y$         | True output or target (e.g., actual price). |
| $\hat{y}$   | Model's prediction or estimate of $y$.    |
| $f(x)$      | The model or function used for predictions.|

---

## **Linear Regression**
- **Function Definition**: A linear model uses the equation:
  
  $$ f_{w,b}(x) = w \cdot x + b $$
  
  - $w$: Slope of the line.
  - $b$: Intercept (where the line crosses the $y$-axis).

- **Graphical Representation**:
  - **Horizontal Axis**: Input feature $x$ (e.g., house size).
  - **Vertical Axis**: Output target $y$ (e.g., house price).
  - **Best-Fit Line**: Represents the function $f(x)$ that minimizes prediction errors.

---

## **Simplified Notation**
- Instead of $f_{w,b}(x)$, we often write $f(x)$ for simplicity.

---

## **Why Use a Linear Function?**
- **Advantages**:
  - Simple and easy to work with.
  - Serves as a foundation for more complex, non-linear models.
- **Example of Non-Linear Models**: Parabolas, curves, etc.

---

## **Types of Linear Regression**
- **Univariate Linear Regression**:
  - **Definition**: A model with one input feature ($x$).
  - **Alternative Name**: Linear regression with one variable.
  - **Example**: Predicting house price based on house size.
- **Multivariate Linear Regression**:
  - **Definition**: A model with multiple input features.
  - **Example**: Predicting house price based on size, number of bedrooms, etc.


